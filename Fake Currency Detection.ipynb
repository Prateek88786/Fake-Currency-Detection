{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4872904,"sourceType":"datasetVersion","datasetId":2825392}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Flatten, Dense, Dropout, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:28:27.444111Z","iopub.execute_input":"2025-01-21T09:28:27.444463Z","iopub.status.idle":"2025-01-21T09:28:27.449133Z","shell.execute_reply.started":"2025-01-21T09:28:27.444435Z","shell.execute_reply":"2025-01-21T09:28:27.448263Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Define dataset root directory\ndataset_root = \"/kaggle/input/indian-currency-dataset/Indian Currency Dataset\"\n\n# Define paths for training and testing\ntrain_dir = os.path.join(dataset_root, 'train')\ntest_dir = os.path.join(dataset_root, 'test')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:28:30.104820Z","iopub.execute_input":"2025-01-21T09:28:30.105093Z","iopub.status.idle":"2025-01-21T09:28:30.108999Z","shell.execute_reply.started":"2025-01-21T09:28:30.105071Z","shell.execute_reply":"2025-01-21T09:28:30.107982Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Data augmentation for training & validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2  # Use 20% of train data for validation\n)\n\n# Load training data (80% of original train data)\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),\n    batch_size=16,\n    class_mode='binary',\n    subset='training'  # Training set (80%)\n)\n\n# Load validation data (20% of original train data)\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),\n    batch_size=16,\n    class_mode='binary',\n    subset='validation'  # Validation set (20%)\n)\n\n# Load test data (No split, only rescale)\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(128, 128),\n    batch_size=16,\n    class_mode='binary',\n    shuffle=False  # Ensure correct label-order mapping\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:28:32.421814Z","iopub.execute_input":"2025-01-21T09:28:32.422122Z","iopub.status.idle":"2025-01-21T09:28:33.011453Z","shell.execute_reply.started":"2025-01-21T09:28:32.422094Z","shell.execute_reply":"2025-01-21T09:28:33.010826Z"}},"outputs":[{"name":"stdout","text":"Found 199 images belonging to 2 classes.\nFound 49 images belonging to 2 classes.\nFound 107 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def build_discriminator():\n    model = Sequential([\n        # First Conv Block\n        Conv2D(32, (3, 3), padding='same', input_shape=(128, 128, 3)),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        MaxPooling2D(pool_size=(2,2)), \n\n        # Second Conv Block\n        Conv2D(64, (3, 3), padding='same'),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        MaxPooling2D(pool_size=(2,2)),\n\n        # Third Conv Block\n        Conv2D(128, (3, 3), padding='same'),\n        BatchNormalization(),\n        LeakyReLU(0.2),\n        MaxPooling2D(pool_size=(2,2)),\n\n        # Fully Connected Layers\n        Flatten(),\n        Dense(128),  \n        LeakyReLU(0.2),\n        Dropout(0.4),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    \n    return model\n\n# Build and compile the Discriminator model\ndiscriminator = build_discriminator()\ndiscriminator.compile(optimizer=Adam(learning_rate=0.0002),\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\n\n# Display model summary\ndiscriminator.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T11:23:44.074099Z","iopub.execute_input":"2025-01-18T11:23:44.074555Z","iopub.status.idle":"2025-01-18T11:23:44.172886Z","shell.execute_reply.started":"2025-01-18T11:23:44.074523Z","shell.execute_reply":"2025-01-18T11:23:44.172239Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_10 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m4,194,432\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_11 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,432</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,288,705\u001b[0m (16.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,288,705</span> (16.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,288,257\u001b[0m (16.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,288,257</span> (16.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Define checkpoint to save the best model\ncheckpoint = ModelCheckpoint(\n    'best_simplified_discriminator.keras',\n    monitor='val_accuracy',\n    save_best_only=True,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T11:23:52.746639Z","iopub.execute_input":"2025-01-18T11:23:52.747028Z","iopub.status.idle":"2025-01-18T11:23:52.752258Z","shell.execute_reply.started":"2025-01-18T11:23:52.746995Z","shell.execute_reply":"2025-01-18T11:23:52.751282Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Train the model with validation data from train set\nhistory = discriminator.fit(\n    train_generator,\n    validation_data=val_generator,  # Use validation split\n    epochs=100,\n    callbacks=[checkpoint],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T11:24:00.025821Z","iopub.execute_input":"2025-01-18T11:24:00.026127Z","iopub.status.idle":"2025-01-18T11:34:29.347695Z","shell.execute_reply.started":"2025-01-18T11:24:00.026104Z","shell.execute_reply":"2025-01-18T11:34:29.346999Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - accuracy: 0.5556 - loss: 1.9549\nEpoch 1: val_accuracy improved from -inf to 0.48980, saving model to best_simplified_discriminator.keras\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 514ms/step - accuracy: 0.5655 - loss: 1.9277 - val_accuracy: 0.4898 - val_loss: 0.7009\nEpoch 2/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5739 - loss: 1.8398\nEpoch 2: val_accuracy improved from 0.48980 to 0.85714, saving model to best_simplified_discriminator.keras\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.5903 - loss: 1.7515 - val_accuracy: 0.8571 - val_loss: 0.6425\nEpoch 3/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5687 - loss: 1.5380\nEpoch 3: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.5795 - loss: 1.5051 - val_accuracy: 0.4898 - val_loss: 0.7068\nEpoch 4/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6512 - loss: 1.0768\nEpoch 4: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 276ms/step - accuracy: 0.6477 - loss: 1.1074 - val_accuracy: 0.4898 - val_loss: 0.7278\nEpoch 5/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5789 - loss: 1.4751\nEpoch 5: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.5834 - loss: 1.4266 - val_accuracy: 0.4898 - val_loss: 0.7664\nEpoch 6/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.6859 - loss: 1.0724\nEpoch 6: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - accuracy: 0.6913 - loss: 1.0514 - val_accuracy: 0.4898 - val_loss: 0.8968\nEpoch 7/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6600 - loss: 0.8398\nEpoch 7: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.6491 - loss: 0.9475 - val_accuracy: 0.4898 - val_loss: 0.7481\nEpoch 8/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7158 - loss: 0.9874\nEpoch 8: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.7142 - loss: 0.9695 - val_accuracy: 0.4898 - val_loss: 0.7686\nEpoch 9/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6892 - loss: 0.8862\nEpoch 9: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.6836 - loss: 0.9124 - val_accuracy: 0.4898 - val_loss: 0.8642\nEpoch 10/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7227 - loss: 0.9282\nEpoch 10: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.7157 - loss: 0.9761 - val_accuracy: 0.5918 - val_loss: 0.7237\nEpoch 11/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6718 - loss: 0.9430\nEpoch 11: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.6742 - loss: 0.9330 - val_accuracy: 0.4898 - val_loss: 0.9459\nEpoch 12/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6912 - loss: 0.6689\nEpoch 12: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.6973 - loss: 0.6900 - val_accuracy: 0.4898 - val_loss: 1.7122\nEpoch 13/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.5837 - loss: 1.5542\nEpoch 13: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.6113 - loss: 1.4455 - val_accuracy: 0.5714 - val_loss: 0.6827\nEpoch 14/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7268 - loss: 1.0208\nEpoch 14: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 290ms/step - accuracy: 0.7226 - loss: 1.0668 - val_accuracy: 0.4898 - val_loss: 2.9013\nEpoch 15/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.6964 - loss: 0.9443\nEpoch 15: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - accuracy: 0.6956 - loss: 0.8962 - val_accuracy: 0.4286 - val_loss: 0.9198\nEpoch 16/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.7288 - loss: 0.8479\nEpoch 16: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.7237 - loss: 0.8488 - val_accuracy: 0.5102 - val_loss: 0.8532\nEpoch 17/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.7458 - loss: 0.8044\nEpoch 17: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 255ms/step - accuracy: 0.7418 - loss: 0.8168 - val_accuracy: 0.4286 - val_loss: 1.1798\nEpoch 18/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7210 - loss: 0.7034\nEpoch 18: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 297ms/step - accuracy: 0.7281 - loss: 0.6964 - val_accuracy: 0.4286 - val_loss: 1.1095\nEpoch 19/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7636 - loss: 0.6547\nEpoch 19: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.7506 - loss: 0.7315 - val_accuracy: 0.4694 - val_loss: 1.8888\nEpoch 20/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.6876 - loss: 1.1771\nEpoch 20: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.7042 - loss: 1.0589 - val_accuracy: 0.8163 - val_loss: 0.4248\nEpoch 21/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7428 - loss: 0.9934\nEpoch 21: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 276ms/step - accuracy: 0.7453 - loss: 0.9733 - val_accuracy: 0.4898 - val_loss: 2.4910\nEpoch 22/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7123 - loss: 0.7954\nEpoch 22: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.7147 - loss: 0.7953 - val_accuracy: 0.4898 - val_loss: 1.1288\nEpoch 23/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8052 - loss: 0.5574\nEpoch 23: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.7947 - loss: 0.6214 - val_accuracy: 0.5306 - val_loss: 1.4130\nEpoch 24/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7633 - loss: 0.6645\nEpoch 24: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.7738 - loss: 0.6264 - val_accuracy: 0.7551 - val_loss: 0.6123\nEpoch 25/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6622 - loss: 0.8761\nEpoch 25: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.6756 - loss: 0.8483 - val_accuracy: 0.5306 - val_loss: 1.8077\nEpoch 26/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8315 - loss: 0.7455\nEpoch 26: val_accuracy did not improve from 0.85714\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.8158 - loss: 0.7936 - val_accuracy: 0.5102 - val_loss: 1.6801\nEpoch 27/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.7765 - loss: 0.7513\nEpoch 27: val_accuracy improved from 0.85714 to 0.87755, saving model to best_simplified_discriminator.keras\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.7645 - loss: 0.7835 - val_accuracy: 0.8776 - val_loss: 0.4505\nEpoch 28/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7161 - loss: 0.6696\nEpoch 28: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 260ms/step - accuracy: 0.7138 - loss: 0.7061 - val_accuracy: 0.7959 - val_loss: 0.4980\nEpoch 29/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7204 - loss: 0.7937\nEpoch 29: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.7163 - loss: 0.8492 - val_accuracy: 0.7755 - val_loss: 0.8649\nEpoch 30/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.8605 - loss: 0.3813\nEpoch 30: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.8537 - loss: 0.4068 - val_accuracy: 0.8571 - val_loss: 0.5380\nEpoch 31/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7178 - loss: 0.9803\nEpoch 31: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.7265 - loss: 0.9186 - val_accuracy: 0.7551 - val_loss: 0.6918\nEpoch 32/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8030 - loss: 0.6664\nEpoch 32: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.7989 - loss: 0.6966 - val_accuracy: 0.7755 - val_loss: 0.6046\nEpoch 33/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8264 - loss: 0.4658\nEpoch 33: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.8175 - loss: 0.5087 - val_accuracy: 0.7755 - val_loss: 0.6525\nEpoch 34/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.7388 - loss: 0.8847\nEpoch 34: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 322ms/step - accuracy: 0.7450 - loss: 0.8846 - val_accuracy: 0.6735 - val_loss: 0.8402\nEpoch 35/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7272 - loss: 1.1361\nEpoch 35: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.7290 - loss: 1.1336 - val_accuracy: 0.7959 - val_loss: 0.4360\nEpoch 36/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7820 - loss: 0.9106\nEpoch 36: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.7746 - loss: 0.9350 - val_accuracy: 0.8163 - val_loss: 0.8923\nEpoch 37/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7775 - loss: 0.5225\nEpoch 37: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.7800 - loss: 0.5662 - val_accuracy: 0.8367 - val_loss: 0.7627\nEpoch 38/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7917 - loss: 0.8586\nEpoch 38: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.7845 - loss: 0.8811 - val_accuracy: 0.8776 - val_loss: 0.6226\nEpoch 39/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7309 - loss: 0.9811\nEpoch 39: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.7328 - loss: 0.9908 - val_accuracy: 0.6531 - val_loss: 1.6415\nEpoch 40/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6760 - loss: 0.9907\nEpoch 40: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.6879 - loss: 0.9564 - val_accuracy: 0.7959 - val_loss: 0.7781\nEpoch 41/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7110 - loss: 0.8225\nEpoch 41: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.7353 - loss: 0.7885 - val_accuracy: 0.7959 - val_loss: 0.9440\nEpoch 42/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7745 - loss: 0.6638\nEpoch 42: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.7934 - loss: 0.6304 - val_accuracy: 0.8163 - val_loss: 1.0953\nEpoch 43/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.8662 - loss: 0.4279\nEpoch 43: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - accuracy: 0.8636 - loss: 0.4355 - val_accuracy: 0.6939 - val_loss: 1.4667\nEpoch 44/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8318 - loss: 0.5966\nEpoch 44: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.8177 - loss: 0.6208 - val_accuracy: 0.8367 - val_loss: 1.1377\nEpoch 45/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7748 - loss: 0.8028\nEpoch 45: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.7693 - loss: 0.7953 - val_accuracy: 0.7551 - val_loss: 0.8658\nEpoch 46/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8053 - loss: 0.5914\nEpoch 46: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.8072 - loss: 0.5831 - val_accuracy: 0.7143 - val_loss: 1.1059\nEpoch 47/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8032 - loss: 0.5181\nEpoch 47: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.7935 - loss: 0.5936 - val_accuracy: 0.7959 - val_loss: 1.0730\nEpoch 48/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8185 - loss: 0.6329\nEpoch 48: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - accuracy: 0.8124 - loss: 0.6219 - val_accuracy: 0.7755 - val_loss: 1.5039\nEpoch 49/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.8012 - loss: 0.5939\nEpoch 49: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 270ms/step - accuracy: 0.8032 - loss: 0.5924 - val_accuracy: 0.7755 - val_loss: 0.8937\nEpoch 50/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8299 - loss: 0.4168\nEpoch 50: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 270ms/step - accuracy: 0.8154 - loss: 0.4650 - val_accuracy: 0.7143 - val_loss: 1.2694\nEpoch 51/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8803 - loss: 0.3776\nEpoch 51: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - accuracy: 0.8702 - loss: 0.4062 - val_accuracy: 0.7755 - val_loss: 1.0606\nEpoch 52/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8248 - loss: 0.5728\nEpoch 52: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.8181 - loss: 0.5963 - val_accuracy: 0.6939 - val_loss: 1.2185\nEpoch 53/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7902 - loss: 0.6268\nEpoch 53: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.7916 - loss: 0.6164 - val_accuracy: 0.7551 - val_loss: 1.7975\nEpoch 54/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8012 - loss: 0.6955\nEpoch 54: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.8076 - loss: 0.6475 - val_accuracy: 0.7755 - val_loss: 2.0058\nEpoch 55/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.8718 - loss: 0.6005\nEpoch 55: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.8694 - loss: 0.5746 - val_accuracy: 0.6531 - val_loss: 1.8294\nEpoch 56/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8725 - loss: 0.3552\nEpoch 56: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 276ms/step - accuracy: 0.8631 - loss: 0.3675 - val_accuracy: 0.6735 - val_loss: 1.2956\nEpoch 57/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8932 - loss: 0.3442\nEpoch 57: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.8824 - loss: 0.3814 - val_accuracy: 0.8367 - val_loss: 1.0228\nEpoch 58/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8440 - loss: 0.5159\nEpoch 58: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - accuracy: 0.8274 - loss: 0.5857 - val_accuracy: 0.7551 - val_loss: 1.6907\nEpoch 59/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8290 - loss: 0.3794\nEpoch 59: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 290ms/step - accuracy: 0.8235 - loss: 0.4038 - val_accuracy: 0.7755 - val_loss: 1.0912\nEpoch 60/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7874 - loss: 0.7608\nEpoch 60: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.7912 - loss: 0.7525 - val_accuracy: 0.7347 - val_loss: 1.8646\nEpoch 61/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8115 - loss: 0.5467\nEpoch 61: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 290ms/step - accuracy: 0.8149 - loss: 0.5381 - val_accuracy: 0.7551 - val_loss: 1.4347\nEpoch 62/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7598 - loss: 0.7034\nEpoch 62: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 279ms/step - accuracy: 0.7693 - loss: 0.7084 - val_accuracy: 0.5918 - val_loss: 2.1571\nEpoch 63/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.7357 - loss: 0.9831\nEpoch 63: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - accuracy: 0.7545 - loss: 0.8939 - val_accuracy: 0.8367 - val_loss: 1.1582\nEpoch 64/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8066 - loss: 0.5275\nEpoch 64: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.8049 - loss: 0.5344 - val_accuracy: 0.7551 - val_loss: 0.9082\nEpoch 65/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7867 - loss: 0.5272\nEpoch 65: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.7861 - loss: 0.5297 - val_accuracy: 0.8367 - val_loss: 0.8550\nEpoch 66/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8513 - loss: 0.4818\nEpoch 66: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.8544 - loss: 0.4852 - val_accuracy: 0.8367 - val_loss: 1.6158\nEpoch 67/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7595 - loss: 0.7129\nEpoch 67: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.7777 - loss: 0.6716 - val_accuracy: 0.8776 - val_loss: 0.5288\nEpoch 68/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8103 - loss: 0.4578\nEpoch 68: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - accuracy: 0.8172 - loss: 0.4490 - val_accuracy: 0.8367 - val_loss: 0.9196\nEpoch 69/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8362 - loss: 0.4148\nEpoch 69: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - accuracy: 0.8451 - loss: 0.4169 - val_accuracy: 0.7143 - val_loss: 2.1104\nEpoch 70/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8472 - loss: 0.4384\nEpoch 70: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.8419 - loss: 0.4728 - val_accuracy: 0.7755 - val_loss: 1.1808\nEpoch 71/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8804 - loss: 0.4941\nEpoch 71: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.8631 - loss: 0.5260 - val_accuracy: 0.7959 - val_loss: 0.8292\nEpoch 72/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7909 - loss: 0.7370\nEpoch 72: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.7972 - loss: 0.7478 - val_accuracy: 0.5918 - val_loss: 2.6615\nEpoch 73/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8459 - loss: 0.8259\nEpoch 73: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.8537 - loss: 0.7784 - val_accuracy: 0.6122 - val_loss: 2.5057\nEpoch 74/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7956 - loss: 0.5598\nEpoch 74: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 271ms/step - accuracy: 0.8135 - loss: 0.5081 - val_accuracy: 0.7143 - val_loss: 2.2561\nEpoch 75/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8559 - loss: 0.4791\nEpoch 75: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.8485 - loss: 0.5404 - val_accuracy: 0.6735 - val_loss: 1.7176\nEpoch 76/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7794 - loss: 0.5873\nEpoch 76: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.7927 - loss: 0.5785 - val_accuracy: 0.6327 - val_loss: 2.6742\nEpoch 77/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9307 - loss: 0.2209\nEpoch 77: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.9125 - loss: 0.2531 - val_accuracy: 0.7347 - val_loss: 2.4875\nEpoch 78/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8744 - loss: 0.3234\nEpoch 78: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.8663 - loss: 0.3390 - val_accuracy: 0.7347 - val_loss: 3.0563\nEpoch 79/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8720 - loss: 0.4172\nEpoch 79: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 267ms/step - accuracy: 0.8705 - loss: 0.4099 - val_accuracy: 0.8571 - val_loss: 1.2238\nEpoch 80/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8230 - loss: 0.6658\nEpoch 80: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.8244 - loss: 0.6410 - val_accuracy: 0.7143 - val_loss: 1.3375\nEpoch 81/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7440 - loss: 0.8564\nEpoch 81: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.7659 - loss: 0.7768 - val_accuracy: 0.8571 - val_loss: 0.9249\nEpoch 82/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8852 - loss: 0.3248\nEpoch 82: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.8786 - loss: 0.3788 - val_accuracy: 0.8163 - val_loss: 0.9483\nEpoch 83/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8516 - loss: 0.3351\nEpoch 83: val_accuracy did not improve from 0.87755\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.8565 - loss: 0.3467 - val_accuracy: 0.8367 - val_loss: 1.2708\nEpoch 84/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8292 - loss: 0.6704\nEpoch 84: val_accuracy improved from 0.87755 to 0.89796, saving model to best_simplified_discriminator.keras\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.8297 - loss: 0.6149 - val_accuracy: 0.8980 - val_loss: 0.4121\nEpoch 85/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8424 - loss: 0.4853\nEpoch 85: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - accuracy: 0.8401 - loss: 0.4885 - val_accuracy: 0.7755 - val_loss: 1.7038\nEpoch 86/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8455 - loss: 0.6027\nEpoch 86: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.8441 - loss: 0.5981 - val_accuracy: 0.7755 - val_loss: 1.0201\nEpoch 87/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8318 - loss: 0.4958\nEpoch 87: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.8261 - loss: 0.5162 - val_accuracy: 0.7143 - val_loss: 1.6950\nEpoch 88/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.8795 - loss: 0.2597\nEpoch 88: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.8804 - loss: 0.2588 - val_accuracy: 0.7755 - val_loss: 1.2882\nEpoch 89/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.8215 - loss: 0.5565\nEpoch 89: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - accuracy: 0.8334 - loss: 0.5543 - val_accuracy: 0.7551 - val_loss: 2.2042\nEpoch 90/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.8292 - loss: 0.5821\nEpoch 90: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.8309 - loss: 0.5702 - val_accuracy: 0.7755 - val_loss: 2.1201\nEpoch 91/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7856 - loss: 0.7062\nEpoch 91: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.7896 - loss: 0.6942 - val_accuracy: 0.7959 - val_loss: 1.0615\nEpoch 92/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.8520 - loss: 0.3495\nEpoch 92: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.8606 - loss: 0.3297 - val_accuracy: 0.8163 - val_loss: 2.4768\nEpoch 93/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8523 - loss: 0.5137\nEpoch 93: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - accuracy: 0.8516 - loss: 0.5246 - val_accuracy: 0.7143 - val_loss: 1.5296\nEpoch 94/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8549 - loss: 0.3145\nEpoch 94: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - accuracy: 0.8606 - loss: 0.3232 - val_accuracy: 0.7959 - val_loss: 1.0713\nEpoch 95/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9074 - loss: 0.2654\nEpoch 95: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.9048 - loss: 0.2971 - val_accuracy: 0.7551 - val_loss: 1.3907\nEpoch 96/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8264 - loss: 0.6562\nEpoch 96: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - accuracy: 0.8279 - loss: 0.6278 - val_accuracy: 0.7347 - val_loss: 2.6802\nEpoch 97/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8698 - loss: 0.4981\nEpoch 97: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.8646 - loss: 0.5085 - val_accuracy: 0.7347 - val_loss: 1.9214\nEpoch 98/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8360 - loss: 0.3816\nEpoch 98: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - accuracy: 0.8364 - loss: 0.4059 - val_accuracy: 0.6531 - val_loss: 4.4725\nEpoch 99/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.8006 - loss: 0.5976\nEpoch 99: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.8074 - loss: 0.5964 - val_accuracy: 0.6939 - val_loss: 2.0910\nEpoch 100/100\n\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7744 - loss: 0.7277\nEpoch 100: val_accuracy did not improve from 0.89796\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 269ms/step - accuracy: 0.7760 - loss: 0.7200 - val_accuracy: 0.6939 - val_loss: 3.3545\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Load the best saved model\nbest_model = tf.keras.models.load_model('best_simplified_discriminator.keras')\n\n# Evaluate on the test dataset\ntest_loss, test_accuracy = best_model.evaluate(test_generator, verbose=1)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:28:43.549055Z","iopub.execute_input":"2025-01-21T09:28:43.549410Z","iopub.status.idle":"2025-01-21T09:28:49.607254Z","shell.execute_reply.started":"2025-01-21T09:28:43.549375Z","shell.execute_reply":"2025-01-21T09:28:49.606576Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 452ms/step - accuracy: 0.8855 - loss: 0.4353\nTest Accuracy: 94.39%\nTest Loss: 0.2374\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nimport os\n\n# Get predictions (1 = Real, 0 = Fake)\npredictions = (best_model.predict(test_generator) > 0.5).astype(int)\ntrue_labels = test_generator.classes\nfilenames = test_generator.filenames  # Get image filenames\n\n# Classification report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(true_labels, predictions, target_names=test_generator.class_indices.keys()))\n\n# Confusion matrix\nprint(\"\\nConfusion Matrix:\\n\")\nconf_matrix = confusion_matrix(true_labels, predictions)\nprint(conf_matrix)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:36:05.994702Z","iopub.execute_input":"2025-01-21T09:36:05.994989Z","iopub.status.idle":"2025-01-21T09:36:09.618304Z","shell.execute_reply.started":"2025-01-21T09:36:05.994968Z","shell.execute_reply":"2025-01-21T09:36:09.617636Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n        fake       1.00      0.90      0.95        59\n        real       0.89      1.00      0.94        48\n\n    accuracy                           0.94       107\n   macro avg       0.94      0.95      0.94       107\nweighted avg       0.95      0.94      0.94       107\n\n\nConfusion Matrix:\n\n[[53  6]\n [ 0 48]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}